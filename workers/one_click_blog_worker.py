# workers/one_click_blog_worker.py
import json
import requests
import xml.etree.ElementTree as ET
import re
from PyQt6.QtCore import QThread, pyqtSignal
from ai_modules import BlogGenerator
from ai_modules.image_searcher import ImageSearcher

class OneClickBlogWorker(QThread):
    """ì›í´ë¦­ ë¸”ë¡œê·¸ ìƒì„±ì„ ìœ„í•œ í†µí•© ì›Œì»¤ (ì¹´í…Œê³ ë¦¬/í‚¤ì›Œë“œ í†µí•© ê²€ìƒ‰ ì§€ì›)"""
    
    finished = pyqtSignal(dict)       # ì™„ì„±ëœ ë¸”ë¡œê·¸ ë°ì´í„°
    error = pyqtSignal(str)           # ì˜¤ë¥˜ ë©”ì‹œì§€
    progress = pyqtSignal(int)        # ì§„í–‰ë¥  (0-100)
    status_changed = pyqtSignal(str)  # ìƒíƒœ ë©”ì‹œì§€
    
    def __init__(self, naver_id, naver_secret, gemini_key, topic, category_id, category_name):
        super().__init__()
        self.naver_id = naver_id
        self.naver_secret = naver_secret
        self.gemini_key = gemini_key
        self.topic = topic
        self.category_id = category_id  
        self.category_name = category_name
        
    def run(self):
        try:
            # 1ë‹¨ê³„: ë‰´ìŠ¤ ê²€ìƒ‰ (0-40%)
            self.status_changed.emit("ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘...")
            self.progress.emit(10)
            
            news_list = self._search_naver_news()
            if not news_list:
                self.error.emit("ê²€ìƒ‰ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            self.progress.emit(40)
            
            # 2ë‹¨ê³„: ë¸”ë¡œê·¸ ìƒì„± (40-80%)
            self.status_changed.emit("AI ë¸”ë¡œê·¸ ìƒì„± ì¤‘...")
            
            blog_data = self._generate_blog(news_list)
            if not blog_data:
                self.error.emit("ë¸”ë¡œê·¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                return
            
            self.progress.emit(80)
            
            # 3ë‹¨ê³„: ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì‚½ì… (80-100%)
            self.status_changed.emit("ê´€ë ¨ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
            
            final_blog = self._add_images(blog_data)
            
            self.progress.emit(100)
            self.status_changed.emit("ì™„ë£Œ!")
            
            # ì™„ì„±ëœ ë¸”ë¡œê·¸ ì „ì†¡
            self.finished.emit(final_blog)
            
        except Exception as e:
            self.error.emit(str(e))
    
    def _search_naver_news(self):
        """ë„¤ì´ë²„ ë‰´ìŠ¤ í†µí•© ê²€ìƒ‰ (ì¹´í…Œê³ ë¦¬ + í‚¤ì›Œë“œ ì§€ì›)"""
        try:
            # ğŸ”§ ê²€ìƒ‰ì–´ ê²°ì • ë¡œì§ ê°œì„ 
            search_query = None
            
            # 1ìˆœìœ„: í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ í‚¤ì›Œë“œ ì‚¬ìš©
            if hasattr(self, 'topic') and self.topic and self.topic.strip():
                search_query = self.topic.strip()
                search_type = "í‚¤ì›Œë“œ"
                
            # 2ìˆœìœ„: ì¹´í…Œê³ ë¦¬ëª…ì´ ìˆìœ¼ë©´ ì¹´í…Œê³ ë¦¬ëª… ì‚¬ìš©  
            elif hasattr(self, 'category_name') and self.category_name and self.category_name.strip():
                search_query = self.category_name.strip()
                search_type = "ì¹´í…Œê³ ë¦¬"
                
            # 3ìˆœìœ„: ì¹´í…Œê³ ë¦¬ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ ê²€ìƒ‰ì–´ ìƒì„±
            elif hasattr(self, 'category_id') and self.category_id:
                category_mapping = {
                    '100': 'ì •ì¹˜',
                    '101': 'ê²½ì œ', 
                    '102': 'ì‚¬íšŒ',
                    '103': 'ìƒí™œë¬¸í™”',
                    '104': 'ì„¸ê³„',
                    '105': 'ITê³¼í•™'
                }
                search_query = category_mapping.get(str(self.category_id), 'ìµœì‹ ë‰´ìŠ¤')
                search_type = "ì¹´í…Œê³ ë¦¬ ë§¤í•‘"
                
            # ìµœí›„ ìˆ˜ë‹¨: ê¸°ë³¸ ê²€ìƒ‰ì–´
            else:
                search_query = 'ìµœì‹ ë‰´ìŠ¤'
                search_type = "ê¸°ë³¸"
            
            # API í‚¤ ê²€ì¦
            if not self.naver_id or not self.naver_secret:
                raise Exception("ë„¤ì´ë²„ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„¤ì • íƒ­ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            
            # ê²€ìƒ‰ì–´ ê¸¸ì´ ì œí•œ (ë„¤ì´ë²„ API ì œí•œ: 100ë°”ì´íŠ¸)
            if len(search_query.encode('utf-8')) > 100:
                search_query = search_query[:30]
                print(f"âš ï¸ ê²€ìƒ‰ì–´ê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ ì¶•ì•½: '{search_query}'")
            
            url = "https://openapi.naver.com/v1/search/news.xml"
            
            params = {
                'query': search_query,
                'display': 50,
                'start': 1,
                'sort': 'date'
            }
            
            headers = {
                'X-Naver-Client-Id': self.naver_id.strip(),
                'X-Naver-Client-Secret': self.naver_secret.strip(),
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            # ğŸ”§ ë””ë²„ê¹… ë¡œê·¸
            print(f"ğŸ” ë„¤ì´ë²„ ë‰´ìŠ¤ ê²€ìƒ‰ ({search_type}): '{search_query}'")
            print(f"ğŸ“¡ API ìš”ì²­: {url}")
            print(f"ğŸ“‹ íŒŒë¼ë¯¸í„°: {params}")
            
            response = requests.get(url, params=params, headers=headers, timeout=15)
            
            # ğŸ”§ ìƒì„¸í•œ HTTP ì˜¤ë¥˜ ì²˜ë¦¬
            if response.status_code == 400:
                raise Exception(
                    f"ë„¤ì´ë²„ API ìš”ì²­ ì˜¤ë¥˜ (HTTP 400)\n"
                    f"ê²€ìƒ‰ì–´: '{search_query}' ({search_type})\n"
                    f"ì›ì¸: ì˜ëª»ëœ íŒŒë¼ë¯¸í„°\n"
                    f"í•´ê²°ë°©ë²•: ê²€ìƒ‰ì–´ë¥¼ ë³€ê²½í•˜ê±°ë‚˜ API í‚¤ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
                )
            elif response.status_code == 401:
                raise Exception(
                    f"ë„¤ì´ë²„ API ì¸ì¦ ì‹¤íŒ¨ (HTTP 401)\n"
                    f"ì›ì¸: Client ID/Secretì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ\n"
                    f"í•´ê²°ë°©ë²•:\n"
                    f"1. ì„¤ì • íƒ­ì—ì„œ ë„¤ì´ë²„ API í‚¤ ì¬í™•ì¸\n"
                    f"2. https://developers.naver.com ì—ì„œ í‚¤ ìƒíƒœ í™•ì¸"
                )
            elif response.status_code == 403:
                raise Exception(
                    f"ë„¤ì´ë²„ API ì ‘ê·¼ ê±°ë¶€ (HTTP 403)\n"
                    f"ì›ì¸: API ì‚¬ìš©ëŸ‰ ì´ˆê³¼ ë˜ëŠ” ì„œë¹„ìŠ¤ ì œí•œ\n"
                    f"í•´ê²°ë°©ë²•: ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ê±°ë‚˜ ë„¤ì´ë²„ ê°œë°œìì„¼í„° í™•ì¸"
                )
            elif response.status_code == 429:
                raise Exception(
                    f"ë„¤ì´ë²„ API ìš”ì²­ í•œë„ ì´ˆê³¼ (HTTP 429)\n"
                    f"ì›ì¸: ë„ˆë¬´ ë§ì€ ìš”ì²­\n"
                    f"í•´ê²°ë°©ë²•: 1ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”"
                )
            elif response.status_code != 200:
                raise Exception(
                    f"ë„¤ì´ë²„ ë‰´ìŠ¤ API ì˜¤ë¥˜: HTTP {response.status_code}\n"
                    f"ì‘ë‹µ ë‚´ìš©: {response.text[:200]}..."
                )
            
            # XML íŒŒì‹±
            try:
                root = ET.fromstring(response.content)
            except ET.ParseError as e:
                raise Exception(f"ë„¤ì´ë²„ API ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {str(e)}")
            
            # ê²€ìƒ‰ ê²°ê³¼ ì¶”ì¶œ
            news_list = []
            items = root.findall('.//item')
            
            if not items:
                # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ ëŒ€ì•ˆ ê²€ìƒ‰
                if search_query != 'ìµœì‹ ë‰´ìŠ¤':
                    print(f"âš ï¸ '{search_query}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ. 'ìµœì‹ ë‰´ìŠ¤'ë¡œ ì¬ê²€ìƒ‰...")
                    return self._fallback_search('ìµœì‹ ë‰´ìŠ¤')
                else:
                    raise Exception(f"'{search_query}' ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            
            for item in items:
                try:
                    news_item = {
                        'title': self._clean_html(item.find('title').text if item.find('title') is not None else ''),
                        'originallink': item.find('originallink').text if item.find('originallink') is not None else '',
                        'link': item.find('link').text if item.find('link') is not None else '',
                        'description': self._clean_html(item.find('description').text if item.find('description') is not None else ''),
                        'pubDate': item.find('pubDate').text if item.find('pubDate') is not None else '',
                        'category': getattr(self, 'category_name', 'ì „ì²´'),
                        'search_query': search_query,
                        'search_type': search_type
                    }
                    
                    # ë¹ˆ ì œëª©ì€ ì œì™¸
                    if news_item['title'].strip():
                        news_list.append(news_item)
                        
                except Exception as e:
                    print(f"âš ï¸ ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹± ì˜¤ë¥˜: {e}")
                    continue
            
            if not news_list:
                raise Exception(f"'{search_query}' ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì²˜ë¦¬í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            print(f"âœ… ë‰´ìŠ¤ ê²€ìƒ‰ ì™„ë£Œ ({search_type}): {len(news_list)}ê°œ ë°œê²¬")
            return news_list
            
        except Exception as e:
            if "ë„¤ì´ë²„" in str(e) or "API" in str(e):
                raise e  # ì´ë¯¸ ì²˜ë¦¬ëœ API ì˜¤ë¥˜
            else:
                raise Exception(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")

    def _fallback_search(self, fallback_query):
        """ëŒ€ì•ˆ ê²€ìƒ‰ (ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ë•Œ)"""
        try:
            url = "https://openapi.naver.com/v1/search/news.xml"
            
            params = {
                'query': fallback_query,
                'display': 30,
                'start': 1,
                'sort': 'date'
            }
            
            headers = {
                'X-Naver-Client-Id': self.naver_id.strip(),
                'X-Naver-Client-Secret': self.naver_secret.strip(),
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            response = requests.get(url, params=params, headers=headers, timeout=10)
            
            if response.status_code != 200:
                raise Exception(f"ëŒ€ì•ˆ ê²€ìƒ‰ ì‹¤íŒ¨: HTTP {response.status_code}")
            
            root = ET.fromstring(response.content)
            news_list = []
            
            for item in root.findall('.//item'):
                news_item = {
                    'title': self._clean_html(item.find('title').text if item.find('title') is not None else ''),
                    'originallink': item.find('originallink').text if item.find('originallink') is not None else '',
                    'link': item.find('link').text if item.find('link') is not None else '',
                    'description': self._clean_html(item.find('description').text if item.find('description') is not None else ''),
                    'pubDate': item.find('pubDate').text if item.find('pubDate') is not None else '',
                    'category': 'ì „ì²´',
                    'search_query': fallback_query,
                    'search_type': 'ëŒ€ì•ˆê²€ìƒ‰'
                }
                
                if news_item['title'].strip():
                    news_list.append(news_item)
            
            print(f"ğŸ”„ ëŒ€ì•ˆ ê²€ìƒ‰ ì™„ë£Œ: {len(news_list)}ê°œ")
            return news_list
            
        except Exception as e:
            raise Exception(f"ëŒ€ì•ˆ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
    
    def _generate_blog(self, news_list):
        """ë¸”ë¡œê·¸ ìƒì„±"""
        try:
            blog_generator = BlogGenerator(self.gemini_key)
            blog_generator.set_news_data(news_list)
            
            # ë‰´ìŠ¤ ì„ íƒ
            top_news = blog_generator._select_top_news()
            if not top_news:
                raise Exception("ë¶„ì„í•  ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸
            additional_info = blog_generator._get_additional_context(top_news)
            
            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            from ai_modules.blog_prompts import BlogPrompts
            prompt = BlogPrompts.get_blog_prompt(top_news, additional_info)
            
            # ë¸”ë¡œê·¸ ìƒì„±
            blog_data = blog_generator._generate_with_sdk(prompt)
            
            # í›„ì²˜ë¦¬
            final_blog = blog_generator._post_process(blog_data, top_news)
            
            return final_blog
            
        except Exception as e:
            raise Exception(f"AI ë¸”ë¡œê·¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def _add_images(self, blog_data):
        """ì´ë¯¸ì§€ ê²€ìƒ‰ ë° ì¶”ê°€"""
        try:
            # ì´ë¯¸ì§€ ê²€ìƒ‰ì–´ê°€ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
            image_keywords = blog_data.get('image_keywords', [])
            
            if image_keywords:
                # settings_managerë¥¼ í†µí•´ ì´ë¯¸ì§€ ê²€ìƒ‰
                from utils import SettingsManager
                settings_manager = SettingsManager()
                
                image_searcher = ImageSearcher(settings_manager)
                images = image_searcher.search_images(image_keywords)
                
                # ë³¸ë¬¸ì—ì„œ [ì´ë¯¸ì§€_N] ë§ˆì»¤ë¥¼ ì‹¤ì œ ì´ë¯¸ì§€ë¡œ êµì²´
                content = blog_data.get('content', '')
                
                for marker, image_list in images.items():
                    if image_list:
                        img = image_list[0]
                        img_html = f'''
<div style="text-align: center; margin: 20px 0;">
    <img src="{img["url"]}" alt="{img["description"]}" style="width:100%;max-width:600px;height:auto;border-radius:8px;">
    <p style="font-size:12px;color:#666;margin-top:5px;">ì‚¬ì§„: {img["photographer"]} ({img["source"]})</p>
</div>'''
                        content = content.replace(f'[{marker}]', img_html)
                    else:
                        # ì´ë¯¸ì§€ ëª» ì°¾ì€ ê²½ìš° ë§ˆì»¤ ì œê±°
                        content = content.replace(f'[{marker}]', '')
                
                blog_data['content'] = content
                blog_data['images'] = images
            else:
                # ì´ë¯¸ì§€ í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ë§ˆì»¤ë§Œ ì œê±°
                content = blog_data.get('content', '')
                content = re.sub(r'\[ì´ë¯¸ì§€_\d+\]', '', content)
                blog_data['content'] = content
                blog_data['images'] = {}
            
            return blog_data
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ê²€ìƒ‰ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰): {e}")
            # ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹¤íŒ¨í•´ë„ ë¸”ë¡œê·¸ëŠ” ì™„ì„±
            content = blog_data.get('content', '')
            content = re.sub(r'\[ì´ë¯¸ì§€_\d+\]', '', content)
            blog_data['content'] = content
            blog_data['images'] = {}
            return blog_data
    
    def _clean_html(self, text):
        """HTML íƒœê·¸ ë° ì—”í‹°í‹° ì œê±°"""
        if not text:
            return ''
        
        # HTML íƒœê·¸ ì œê±°
        text = re.sub(r'<[^>]+>', '', text)
        
        # HTML ì—”í‹°í‹° ë””ì½”ë”©
        text = text.replace('&lt;', '<').replace('&gt;', '>')
        text = text.replace('&amp;', '&').replace('&quot;', '"')
        text = text.replace('&#39;', "'")
        
        return text.strip()
